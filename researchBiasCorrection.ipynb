{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1S9Il690eEvtaVxgYnJFzpImRLpw5L_J-",
      "authorship_tag": "ABX9TyNTCC4qrpmnKjknq/OCSg7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sath08/researchProject/blob/main/researchBiasCorrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cftime"
      ],
      "metadata": {
        "id": "PNcVhstnMtgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e72ab53-2635-4845-a46b-ca711332b910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cftime\n",
            "  Downloading cftime-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: numpy>1.13.3 in /usr/local/lib/python3.10/dist-packages (from cftime) (1.26.4)\n",
            "Downloading cftime-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime\n",
            "Successfully installed cftime-1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmjpPrOpHTEL"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cython\n",
        "import cftime\n",
        "from scipy.io import netcdf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_calendar(dataset):\n",
        "\n",
        "  # Place all of the dates that should be removed into a boolean.\n",
        "  removed_times = ~(((dataset.time.dt.month == 2) & (dataset.time.dt.day == 29)) | ((dataset.time.dt.month == 2) & (dataset.time.dt.day == 30)) | ((dataset.time.dt.month == 1) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 3) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 3) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 5) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 7) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 8) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 10) & (dataset.time.dt.day == 31)) | ((dataset.time.dt.month == 12) & (dataset.time.dt.day == 31)))\n",
        "\n",
        "  # Return the dataset with the dates from removed_times excluded.\n",
        "  return dataset.isel(time = removed_times)"
      ],
      "metadata": {
        "id": "pjQ3lPslM-6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_bias_correction():\n",
        "    # Open and calibrate past_gcm dataset.\n",
        "    past_gcm = xr.open_dataset(\n",
        "        \"/content/drive/MyDrive/Sathkrith_Segu_LumiereSummerProject/past_gcm/HADGEM_GCM_past.nc\",\n",
        "        decode_times=False,\n",
        "    )\n",
        "    past_gcm = xr.decode_cf(past_gcm)\n",
        "    past_gcm = fix_calendar(past_gcm)\n",
        "\n",
        "    # Open and calibrate future_gcm dataset.\n",
        "    future_gcm = xr.open_dataset(\n",
        "        \"/content/drive/MyDrive/Sathkrith_Segu_LumiereSummerProject/future_gcm/ssp585/HADGEM_GCM_future.nc\",\n",
        "        decode_times=False,\n",
        "    )\n",
        "    future_gcm = xr.decode_cf(future_gcm)\n",
        "    future_gcm = fix_calendar(future_gcm)\n",
        "\n",
        "    # Open era5 dataset.\n",
        "    era5 = xr.open_dataset(\n",
        "        \"/content/drive/MyDrive/Sathkrith_Segu_LumiereSummerProject/era5/ERA5_1980.nc\"\n",
        "    )\n",
        "    for i in range(34):\n",
        "        era5CurrYear = xr.open_dataset(\n",
        "            \"/content/drive/MyDrive/Sathkrith_Segu_LumiereSummerProject/era5/ERA5_\"\n",
        "            + str(1981 + i)\n",
        "            + \"_xarray.nc\"\n",
        "        )\n",
        "        era5 = xr.concat([era5, era5CurrYear], dim=\"time\")\n",
        "\n",
        "    # Adjust past_gcm and future_gcm datasets to match era5.\n",
        "    past_gcm_2015_val = future_gcm.sel(time=slice(\"2015-01-01\", \"2015-01-01\"))\n",
        "    past_gcm = past_gcm.sel(time=slice(\"1980-01-01\", \"2014-12-30\"))\n",
        "    future_gcm = xr.concat([past_gcm_2015_val, future_gcm], dim=\"time\")\n",
        "\n",
        "    # 1:1 copy, not a reference, of the future_gcm so it can be modified.\n",
        "    future_gcm_BC_copy = future_gcm.copy()\n",
        "\n",
        "    # Dictionary to store variables for each month.\n",
        "    month_variables = {}\n",
        "\n",
        "    for i in tqdm(range(1, 13)):\n",
        "\n",
        "        # Variable name for each month.\n",
        "        variable_name = f\"month_{i}\"\n",
        "\n",
        "        # A month of data from the future to be bias corrected.\n",
        "        future_gcm_BC_copy_month = future_gcm_BC_copy.sel(\n",
        "            time=future_gcm_BC_copy[\"time.month\"] == i\n",
        "        )\n",
        "\n",
        "        past_gcm_month = past_gcm.sel(time=past_gcm[\"time.month\"] == i)[\"tas\"]\n",
        "        future_gcm_month = future_gcm.sel(time=future_gcm[\"time.month\"] == i)[\"tas\"]\n",
        "        era5_gcm_month = era5.sel(time=era5[\"time.month\"] == i)[\"t2m\"]\n",
        "\n",
        "        # latitude loops\n",
        "        for lat in range(len(past_gcm.lat)):\n",
        "\n",
        "            # Converts the latitude value at index phi into a float in the variable lat_phi\n",
        "            lat = past_gcm.lat[lat].values\n",
        "\n",
        "            # longitude loops\n",
        "            for lon in range(len(gcm_P.lon)):\n",
        "\n",
        "                # All the temperatures from month i at grid cell lat x lon sorted by temperature\n",
        "                past_month_temp_grid_cell_sorted = np.sort(past_gcm_month[:, phi, L])\n",
        "                future_month_temp_grid_cell_sorted = np.sort(future_gcm_month[:, phi, L])\n",
        "                era5_month_temp_grid_cell_sorted = np.sort(era5_gcm_month[:, phi, L])\n",
        "\n",
        "                # Creating a copy of future data\n",
        "                future_gcm_month_cell = future_gcm_month[:, phi, L].values\n",
        "\n",
        "                # Creates an array from 1/arr length to 1 which will be used for the percentile classification of temperatures\n",
        "                # ECDF = Emperical Cumulative Distribution Function\n",
        "                # First paramater (1) is the numerator for the index.\n",
        "                # TODO understand the ECDF on Youtube Videos\n",
        "                ecdf_past = np.arange(1, len(past_month_temp_grid_cell_sorted) + 1) / len(\n",
        "                    past_month_temp_grid_cell_sorted\n",
        "                )\n",
        "                ecdf_future = np.arange(1, len(future_month_temp_grid_cell_sorted) + 1) / len(\n",
        "                    future_month_temp_grid_cell_sorted\n",
        "                )\n",
        "                ecdf_era = np.arange(1, len(era5_month_temp_grid_cell_sorted) + 1) / len(\n",
        "                    era5_month_temp_grid_cell_sorted\n",
        "                )\n",
        "\n",
        "                # Contains zeros in which we are going to save the Bias corrected values\n",
        "                empty_future_gcm_month_cell = np.zeros(len(future_gcm_month_cell))\n",
        "\n",
        "                # Loops through every future PV cell datapoint in the chronological order\n",
        "                for i in range(len(future_gcm_month_cell)):\n",
        "                    # Try catch\n",
        "                    try:\n",
        "                        # Does the ECDF (three arrows) mapping\n",
        "                        empty_future_gcm_month_cell[i] = era5_month_temp_grid_cell_sorted[\n",
        "                            np.where(past_month_temp_grid_cell_sorted <= future_month_temp_grid_cell_sorted[i])[0][-1]\n",
        "                        ]  ### This is the main ECDF BC function.\n",
        "                    except IndexError:\n",
        "                        # If the condition is not fulfilled, it means that we found a value that is smaller than all of the data from the past which means that we need to use the first\n",
        "                        # value in the sorted past which is the lowest temperature we have seen\n",
        "                        empty_future_gcm_month_cell[i] = era5_month_temp_grid_cell_sorted[0]\n",
        "                # Saves all of the datapoints for the latitude and longitude to the future_gcm_BC_copy_month\n",
        "                future_gcm_BC_copy_month[PV].loc[dict(lat=lat, lon=lon)] = empty_future_gcm_month_cell\n",
        "\n",
        "        # Adds 1 month of the BC data to the variables dictionary\n",
        "        month_variables[variable_name] = future_gcm_BC_copy_month\n",
        "\n",
        "    # merge the datasets:\n",
        "    futr_PV_corr = xr.merge(\n",
        "        [\n",
        "            variables[\"month_1\"],\n",
        "            variables[\"month_2\"],\n",
        "            variables[\"month_3\"],\n",
        "            variables[\"month_4\"],\n",
        "            variables[\"month_5\"],\n",
        "            variables[\"month_6\"],\n",
        "            variables[\"month_7\"],\n",
        "            variables[\"month_8\"],\n",
        "            variables[\"month_9\"],\n",
        "            variables[\"month_10\"],\n",
        "            variables[\"month_11\"],\n",
        "            variables[\"month_12\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # save the dataset:\n",
        "    futr_PV_corr.to_netcdf(\n",
        "        \"/content/drive/MyDrive/Sathkrith_Segu_LumiereSummerProject/BC_dataset/HADGEM3_BC.nc\"\n",
        "    )\n",
        "    return"
      ],
      "metadata": {
        "id": "KoYwzF2bUkiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_bias_correction()"
      ],
      "metadata": {
        "id": "wpmUH4lzn4WE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}